\BOOKMARK [2][]{Outline0.1}{Introduction}{}% 1
\BOOKMARK [2][]{Outline0.2}{No Attention [Equal Attention?]}{}% 2
\BOOKMARK [2][]{Outline0.3}{Dot product Attention}{}% 3
\BOOKMARK [2][]{Outline0.4}{Additive Attention}{}% 4
\BOOKMARK [2][]{Outline0.5}{Location Aware Attention}{}% 5
\BOOKMARK [2][]{Outline0.6}{2D Location Aware Attention}{}% 6
\BOOKMARK [2][]{Outline0.7}{Location Aware Recurrent Attention}{}% 7
\BOOKMARK [2][]{Outline0.8}{Coverage mechanism Attention}{}% 8
\BOOKMARK [2][]{Outline0.9}{Coverage mechanism location aware Attention}{}% 9
\BOOKMARK [2][]{Outline0.10}{Multi-Head Attention}{}% 10
\BOOKMARK [2][]{Outline0.11}{Multi Head Dot Product Attention}{}% 11
\BOOKMARK [2][]{Outline0.12}{Multi Head location based Attention}{}% 12
\BOOKMARK [2][]{Outline0.13}{Multi Head multi resolution location based Attention}{}% 13
